# -*- coding: utf-8 -*-
"""prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FFDmBcx_Qz-YBWvyZImbB734dA50n_w2
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import joblib

df_cleaned = pd.read_csv('cleaned_employee_data.csv')
df_cleaned.head()

scaler = joblib.load("scaler.pkl")
model = joblib.load("svm_model.pkl")
X_columns = joblib.load("x_columns.pkl")

# Filter data karyawan yang masih aktif
current_employees = df_cleaned[df_cleaned['Attrition'] == 0].copy()
current_employees.reset_index(drop=True, inplace=True)

# Buat dataframe baru tanpa kolom target
X = current_employees.drop(columns=['Attrition'])

# Identifikasi kolom kategori
categorical_cols = X.select_dtypes(include=['object']).columns

# One-hot encoding
X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)

# Tambahkan kolom yang hilang agar sesuai dengan data training
missing_cols = set(X_columns) - set(X_encoded.columns)
for col in missing_cols:
    X_encoded[col] = 0

# Pastikan urutan kolom sama seperti saat training
X_encoded = X_encoded[X_columns]

# Normalisasi (scaling)
X_scaled = scaler.transform(X_encoded)

current_employees.head()

"""Prediksi 10 karyawan dengan probabilitas tertinggi untuk meninggalkan perusahaan"""

predicted_attrition_risk = model.predict(X_scaled)
current_employees['PredictedAttrition'] = predicted_attrition_risk
current_employees.sort_values(by='PredictedAttrition', ascending=False).head(10)